# Anatomy-CoT: Teaching MLLMs to Reason in Radiology

### ‚û°Ô∏è **[Visit the Official Project Page for a Live Demo!](https://vesdas.github.io/Anatomy-CoT/)**

---

This repository contains the official implementation for our paper: **Anatomy-CoT: Teaching MLLMs to Reason in Radiology**.

Our project page provides a more comprehensive overview, including:
*   üé• A video demonstration of our framework.
*   üî¨ Detailed explanations of our approach and key findings.
*   üìä Interactive comparisons and qualitative results.

![Anatomy-CoT Framework](https://vesdas.github.io/Anatomy-CoT/static/images/framework_v1.png)

## Abstract
Chain-of-Thought (CoT) has shown promise in enabling multimodal large language models to solve complex problems. However, CoT suffers from an over-reliance on textual cues and struggles to adapt general reasoning capabilities to highly specialized domains such as radiology. In this paper, we introduce Anatomy-CoT, a multi-step reasoning framework that follows real-world radiology pedagogical practices and incorporates visual grounding to enhance interpretability for radiologists. Comprehensive evaluations show that Anatomy-CoT delivers transparent reasoning, achieves an 11.7% improvement over vanilla CoT, and generalizes robustly to out-of-domain radiology images.

<!-- ## Setup & Usage

To get started, please clone this repository and set up the environment. -->

<!-- ```bash
# Clone the repository
git clone https://github.com/vesdas/Anatomy-CoT-Teaching-MLLMs-to-Reason-in-Radiology.git
cd Anatomy-CoT-Teaching-MLLMs-to-Reason-in-Radiology -->

# TODO: Add your environment setup commands here
# For example:
# conda create -n anatomy_cot python=3.9
# conda activate anatomy_cot
# pip install -r requirements.txt